{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from models.lxrt_adaptive import VQAModel_Adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'adapt_span_enabled': True, 'attn_span': 1024, 'adapt_span_loss_coeff': 0.000005, \n",
    "          'adapt_span_ramp': 32, 'adapt_span_init': 0.002, 'adapt_span_cache': True, 'nb_heads': 12,\n",
    "          'bs': 256, 'mask_size': [20,36], 'sparse_enabled': True, 'num_attention_heads': 4,\n",
    "          'layer_sizes': {'lang':6,'cross':4,'vision':4}, 'from_scratch': False }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0203 20:25:08.482328 140630299241344 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/u37216/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0203 20:25:08.920816 140630299241344 lxmert_utils.py:200] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/u37216/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "I0203 20:25:08.927352 140630299241344 lxmert_utils.py:208] extracting archive file /home/u37216/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /home/u37216/tmp/tmpg_oh5t3j\n",
      "I0203 20:25:16.659927 140630299241344 lxmert_utils.py:215] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LXRT encoder with 6 l_layers, 4 x_layers, and 4 r_layers.\n",
      "Using Adaptive Variant\n",
      "Sparse Enabled\n"
     ]
    }
   ],
   "source": [
    "model = VQAModel_Adaptive(3129,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_feats = torch.rand(256,20,768)\n",
    "lang_attention_mask = torch.rand(256,1,1,20)\n",
    "visn_feats = torch.rand(256,36,768)\n",
    "visn_attention_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ml[0](lang_feats,lang_attention_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 20, 768])\n"
     ]
    }
   ],
   "source": [
    "class LayerDrop_Bert(nn.Module):\n",
    "    def __init__(self, module_list, drop_pct=0.2):\n",
    "        super().__init__()\n",
    "        self.module_list = module_list\n",
    "        self.drop_pct = int(drop_pct*10)\n",
    "        self.length = len(module_list)\n",
    "    \n",
    "    def forward(self, feats, attention_mask):\n",
    "        x = torch.randint(0, self.length, (self.drop_pct,))\n",
    "        print(x)\n",
    "        for index, layer in enumerate(self.module_list):\n",
    "            if index not in x:\n",
    "                feats = layer(feats, attention_mask) \n",
    "                print(index)\n",
    "        return feats\n",
    "    \n",
    "class LayerDrop_Cross(nn.Module):\n",
    "    def __init__(self, module_list, drop_pct=0.2):\n",
    "        super().__init__()\n",
    "        self.module_list = module_list\n",
    "        self.drop_pct = int(drop_pct*10)\n",
    "        self.length = len(module_list)\n",
    "    \n",
    "    def forward(self, lang_feats, lang_attention_mask, visn_feats, visn_attention_mask):\n",
    "        x = torch.randint(0, self.length, (self.drop_pct,)) \n",
    "        print(x)\n",
    "        for index, layer in enumerate(self.module_list):\n",
    "            if index not in x:\n",
    "                lang_feats, visn_feats = layer(lang_feats, lang_attention_mask,\n",
    "                                               visn_feats, visn_attention_mask) # \n",
    "                print(index)\n",
    "        return lang_feats, visn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LayerDrop_Bert(layer_ml,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l(lang_feats, lang_attention_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_ml = model.lxrt_encoder.model.bert.encoder.x_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LayerDrop_Cross(cross_ml,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l(lang_feats=lang_feats, lang_attention_mask=lang_attention_mask,\n",
    "                      visn_feats=visn_feats, visn_attention_mask=visn_attention_mask)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cross_ml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
